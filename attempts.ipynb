{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Materials\n",
    "* [Bunch of articles](http://www.mitpressjournals.org/doi/pdf/10.1162/neco.1993.5.6.954) - I strongly recomment this resource, cause it hosts most actual (by year of publishing) articles.\n",
    "* [realization on C++](https://github.com/BelBES/ESOINN)\n",
    "* [ESOINN algorithm](http://cs.nju.edu.cn/rinc/SOINN/e-soinn.pdf)\n",
    "* [Detailed article](http://www.haselab.info/soinn-e.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ESOINN node class\n",
    "##### Fields\n",
    "* feature_vector – weights\n",
    "* accamulate_signals – number of signals\n",
    "* total_points – points $\\neq$ number of signals\n",
    "* density – mean accumulated signals\n",
    "* subclass_id – mark for subclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ESOINN_Node:\n",
    "    def __init__(self, feature_vector=()):\n",
    "        self.feature_vector = np.array(feature_vector, dtype=float)  \n",
    "        self.accamulate_signals = 0\n",
    "        self.total_points = 0\n",
    "        self.density = 0\n",
    "        self.subclass_id = -1\n",
    "    \n",
    "    def update_accamulate_signals(self, n=1):\n",
    "        self.accamulate_signals += 1\n",
    "    \n",
    "    def update_points(self, points):\n",
    "        self.total_points += points\n",
    "        \n",
    "    def update_density(self, coeff=None):\n",
    "        self.density = self.total_points/(coeff if coeff else self.accamulate_signals)\n",
    "        \n",
    "    def update_feature_vector(self, signal, coeff):\n",
    "        self.feature_vector += coeff*(signal - self.feature_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ESOINN Neural Network class\n",
    "To start lerning use: `fit()` method, for clasterization use `predict()`.\n",
    "\n",
    "##### Params:\n",
    "To create new `EnhancedSelfOrganizingIncrementalNN` object – initialize it with first two nodes (`init_nodes`) randomly.\n",
    "\n",
    "##### Hiperparams:\n",
    "* `C1`, `C2` – coefficents for noise deletion.\n",
    "* `learning_step` – number of iterations before remove old ages and find classes ($\\lambda$ in literature).\n",
    "* `max_age` – for edges.\n",
    "* `forget` – specify which N is used in density calculation.\n",
    "* `metrics` – lambda(x, y, axis)\n",
    "* `radius_cut_off` – degree of neighbors' nodes.\n",
    "* `learning_rate_winner` \n",
    "* `learning_rate_winner_neighbor`\n",
    "\n",
    "##### Fields:\n",
    "* `ids` – last given id for nodes (should be unique)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnhancedSelfOrganizingIncrementalNN:\n",
    "    def __init__(self, init_nodes, C1=0.001, C2=1, learning_step=200, max_age=50, \n",
    "                 metrics=lambda x,y,axis=0: np.sqrt(np.sum(np.square(np.array(x) - np.array(y)), axis=axis)),\n",
    "                 forget=False, radius_cut_off=1, learning_rate_winner=lambda t: 1/t, \n",
    "                 learning_rate_winner_neighbor=lambda t: 1/(100*t)):\n",
    "        self.C1 = C1\n",
    "        self.C2 = C2\n",
    "        self.learning_step = learning_step\n",
    "        self.max_age = max_age\n",
    "        self.count_signals = 2\n",
    "        self.metrics = metrics\n",
    "        self.forget = forget\n",
    "        self.unique_id = 2\n",
    "        self.rc = radius_cut_off\n",
    "        self.rate = learning_rate_winner\n",
    "        self.rate_neighbor = learning_rate_winner_neighbor\n",
    "        \n",
    "        self.nodes = {i: ESOINN_Node(init_nodes[i]) for i in (0, 1)}\n",
    "        # @TODO: use { node_id: { neighbor_id: age } } instead of self.neighbors, self.edges\n",
    "        self.neighbors = {}  # key = id, value = set of neighbors' ids\n",
    "        self.edges = {}  # key = tuple(2), where t[0] < t[1], value = age/None\n",
    "    \n",
    "    def fit(self, input_signal):\n",
    "        self.count_signals += 1\n",
    "        \n",
    "        winners_ids, distances = self.find_winners(input_signal)\n",
    "        # @TODO: do not use thesholds list, calc it inplace\n",
    "        thresholds = [self.calc_threshold(input_signal, winners_ids[i]) for i in (0, 1)]\n",
    "        if distances[0] > thresholds[0] or distances[1] > thresholds[1]:\n",
    "            self.create_node(input_signal)\n",
    "            return\n",
    "        \n",
    "        self.update_edges_age(winners_ids[0])\n",
    "        self.build_connection(winners_ids)\n",
    "        \n",
    "        # do it one time only 'cause it takes long time\n",
    "        winner_neighbors = self.find_neighbors(winners_ids[0], depth=self.rc)\n",
    "        # @CHECKME: обновление количества побед нейрона - не знаю куда поставить, но точно до подсчета плотности\n",
    "        self.nodes[winners_ids[0]].update_accamulate_signals()\n",
    "        \n",
    "        self.update_neuron_density(winners_ids[0], winner_neighbors)\n",
    "        self.update_neurons_feature_vector(winners_ids[0], input_signal, winner_neighbors)\n",
    "        self.remove_old_ages()\n",
    "        \n",
    "        if not self.count_signals % self.learning_step:\n",
    "            self.separate_subclasses()  # @TODO: algorithm 3.1\n",
    "            self.remove_noise()  # @TODO: noize removal\n",
    "    \n",
    "    def find_winners(self, input_signal):\n",
    "        # @FIXME: inf coef and separate variables for each winner\n",
    "        winner1 = float('inf')\n",
    "        winner1_id = -1\n",
    "        winner2 = float('inf')\n",
    "        winner2_id = -1\n",
    "        for node_id in self.nodes:\n",
    "            dist = self.metrics(input_signal, self.nodes[node_id].feature_vector)\n",
    "            if dist <= winner1:\n",
    "                winner1, winner2 = dist, winner1\n",
    "                winner2_id = winner1_id\n",
    "                winner1_id = node_id\n",
    "            elif dist < winner2:\n",
    "                winner2 = dist\n",
    "                winner2_id = node_id\n",
    "        return [winner1_id, winner2_id], [winner1, winner2]\n",
    "    \n",
    "    def find_neighbors(self, start_node_id, depth=1) -> set():\n",
    "        visited = {start_node_id}\n",
    "        queue = list(self.neighbors.get(start_node_id, set()) - visited)\n",
    "        while depth and queue:\n",
    "            depth -= 1\n",
    "            for vertex in queue.copy():  # @FIXME: do not use copy!\n",
    "                visited.add(vertex)\n",
    "                queue.remove(vertex)\n",
    "                queue.extend([node for node in self.neighbors[vertex] - visited if node not in visited])\n",
    "        return visited - {start_node_id}    \n",
    "    \n",
    "    def calc_threshold(self, input_signal, winner_id):\n",
    "        neighbors = self.neighbors.get(winner_id, None)\n",
    "        if neighbors:\n",
    "            return np.max([\n",
    "                self.metrics(self.nodes[winner_id].feature_vector, self.nodes[neighbor_id].feature_vector) \n",
    "                for neighbor_id in self.find_neighbors(winner_id, depth=self.rc)\n",
    "            ])\n",
    "        else:\n",
    "            return self.find_winners(self.nodes[winner_id].feature_vector)[1][1]  # 'cause first winner is always current node\n",
    "    \n",
    "    def create_node(self, input_signal):  \n",
    "        self.nodes[self.unique_id] = ESOINN_Node(input_signal)\n",
    "        self.unique_id += 1  # to provide unique ids for each neuron\n",
    "    \n",
    "    def update_edges_age(self, node_id, step=1):\n",
    "        neighbors = self.find_neighbors(node_id, depth=self.rc)\n",
    "        for neighbor_id in neighbors:\n",
    "            pair_id = min(node_id, neighbor_id), max(node_id, neighbor_id)\n",
    "            self.edges[pair_id] += 1\n",
    "                \n",
    "    # algorithm 3.2\n",
    "    def build_connection(self, winners_ids):\n",
    "        winners_classes = [self.nodes[winners_ids[i]].subclass_id for i in [0, 1]]\n",
    "        if winners_classes[0] == -1 or winners_classes[1] == -1 or winners_classes[0] == winners_classes[1] or self.merge_subclass_condition(winners_ids):\n",
    "            self.combine_subclasses(winners_ids)\n",
    "            self.create_edges(winners_ids)\n",
    "        else:\n",
    "            self.remove_edges(winners_ids)\n",
    "                \n",
    "    def create_edges(self, nodes_ids):\n",
    "        for node_id in nodes_ids:\n",
    "            if node_id not in self.neighbors:\n",
    "                self.neighbors[node_id] = set()\n",
    "            for insert_id in nodes_ids:\n",
    "                if insert_id != node_id:\n",
    "                    self.neighbors[node_id] |= {insert_id}\n",
    "                    nodes_pair = (min(node_id, insert_id), max(node_id, insert_id))\n",
    "                    self.edges[nodes_pair] = 0\n",
    "                    \n",
    "    # @CHECKME: with index usage\n",
    "#     def create_edges(self, nodes_ids):\n",
    "#         for node_index in range(len(nodes_ids)):\n",
    "#             if nodes_ids[node_index] not in self.neighbors:\n",
    "#                 self.neighbors[nodes_ids[node_index]] = set()\n",
    "#             for insert_index in range(node_index+1, len(nodes_ids)):\n",
    "#                 if insert_index != node_index:\n",
    "#                     self.neighbors[nodes_ids[node_index]] |= {nodes_ids[insert_index]}\n",
    "#                     nodes_pair = (nodes_ids[node_index], nodes_ids[insert_index])\n",
    "#                     self.edges[nodes_pair] = 0\n",
    "    \n",
    "    # @FIXME: keys repeats in for cycle\n",
    "    def remove_edges(self, nodes_ids):\n",
    "        for node_id in nodes_ids:\n",
    "            for remove_id in nodes_ids:\n",
    "                if remove_id != node_id and remove_id in self.neighbors[node_id]:\n",
    "                    self.neighbors[node_id] -= {remove_id}\n",
    "                    nodes_pair = (min(node_id, remove_id), max(node_id, remove_id))\n",
    "                    if nodes_pair in self.edges:\n",
    "                        del self.edges[nodes_pair]\n",
    "            if not self.neighbors[node_id]:\n",
    "                del self.neighbors[node_id]\n",
    "\n",
    "    # @CHECKME: with index usage\n",
    "#     def remove_edges(self, nodes_ids):\n",
    "#         for node_index in range(len(nodes_ids)):\n",
    "#             for remove_index in range(node_index+1, len(nodes_ids)):\n",
    "#                 if remove_index != node_index and nodes_ids[remove_index] in self.neighbors[nodes_ids[node_index]]:\n",
    "#                     self.neighbors[nodes_ids[node_index]] -= {nodes_ids[remove_index]}\n",
    "#                     nodes_pair = (nodes_ids[node_index], nodes_ids[remove_index])\n",
    "#                     if nodes_pair in self.edges:\n",
    "#                         del self.edges[nodes_pair]\n",
    "#             if not self.neighbors[nodes_ids[node_index]]:\n",
    "#                 del self.neighbors[nodes_ids[node_index]]\n",
    "                         \n",
    "    def update_node_points(self, winner_id, neighbors):\n",
    "        if neighbors:\n",
    "            mean_dist2neighbors = 1/len(neighbors)*np.sum([\n",
    "                self.metrics(self.nodes[winner_id].feature_vector, self.nodes[neighbor_id].feature_vector)\n",
    "                for neighbor_id in neighbors\n",
    "            ])\n",
    "        self.nodes[winner_id].update_points(1/(1 + (0 if not neighbors else mean_dist2neighbors))**2)\n",
    "\n",
    "    def update_neuron_density(self, winner_id, neighbors):\n",
    "        self.update_node_points(winner_id, neighbors)\n",
    "        self.nodes[winner_id].update_density((self.count_signals if self.forget else None))\n",
    "\n",
    "    def update_neurons_feature_vector(self, winner_id, input_signal, neighbors):\n",
    "        acc_signal = self.nodes[winner_id].accamulate_signals\n",
    "        self.nodes[winner_id].update_feature_vector(input_signal, self.rate(acc_signal))\n",
    "        coeff_neighbors = self.rate_neighbor(acc_signal)\n",
    "        for neighbor_id in neighbors:\n",
    "            self.nodes[neighbor_id].update_feature_vector(input_signal, coeff_neighbors)\n",
    "    \n",
    "    # @CHECKME: use remove_edges() - but no test done\n",
    "    def remove_old_ages(self):\n",
    "        for edge in self.edges.copy():\n",
    "            if self.edges[edge] > self.max_age:\n",
    "                self.remove_edges(edge)\n",
    "    \n",
    "    def calc_mean_density_in_subclass(self, node_id):\n",
    "        neighbors = self.find_neighbors(node_id, depth=len(self.neighbors[node_id]))\n",
    "        return 1/len(neighbors)*np.sum([self.nodes[node_id].density for node_id in neighbors])\n",
    "    \n",
    "    def calc_alpha(self, node_id, apex_density):\n",
    "        mean_density = calc_mean_density_in_subclass(node_id)\n",
    "        if 2*mean_density >= apex_density:\n",
    "            return 0\n",
    "        elif 3*mean_density >= apex_density:\n",
    "            return 0.5\n",
    "        return 1\n",
    "    \n",
    "    def merge_subclass_condition(self, winners_ids):\n",
    "        min_winners_density = min(self.nodes[winners_ids[0]].density, self.nodes[winners_ids[1]].density)\n",
    "        return (\n",
    "            min_winners_density > self.calc_alpha(\n",
    "                winners_ids[0],\n",
    "                self.nodes[self.nodes[winners_ids[0]].subclass_id].density\n",
    "            )\n",
    "        ) or (\n",
    "            min_winners_density > self.calc_alpha(\n",
    "                winners_ids[1], \n",
    "                self.nodes[self.nodes[winners_ids[1]].subclass_id].density\n",
    "            )\n",
    "        )\n",
    "    \n",
    "    def change_class_id(self, node_id, class_id):\n",
    "        neighbors = self.find_neighbors(node_id, depth=-1)\n",
    "        for nieghbor_id in neighbors:\n",
    "            self.nodes[neighbor_id].subclass_id = class_id\n",
    "    \n",
    "    def combine_subclasses(self, nodes_ids):\n",
    "        nodes = [self.nodes[nodes_ids[0]], self.nodes[nodes_ids[1]]]\n",
    "        subclass_ids = [nodes[0].subclass_id, nodes[1].subclass_id]\n",
    "        if subclass_ids[0] == -1 and subclass_ids[1] == -1:\n",
    "            for node in nodes:\n",
    "                node.subclass_id = nodes_ids[0]\n",
    "        elif subclass_ids[0] != subclass_ids[1]:\n",
    "            if subclass_ids[0] == -1:\n",
    "                change_class_id(nodes_ids[0], subclass_ids[1])\n",
    "            else:\n",
    "                change_class_id(nodes_ids[1], subclass_ids[0])\n",
    "    \n",
    "    def is_extremum(self, node_id) -> int:\n",
    "        neighbors = self.find_neighbors(node_id)\n",
    "        current_density = self.nodes[node_id].density\n",
    "        local_min = False\n",
    "        local_max = False\n",
    "        for neighbor_id in neighbors:\n",
    "            if local_min and local_max:\n",
    "                return\n",
    "            neighbor_density = self.nodes[neighbor_id].density\n",
    "            if current_density > neighbor_density:\n",
    "                local_max = True\n",
    "            elif current_density < neighbor_density:\n",
    "                local_min = True\n",
    "            else:\n",
    "                raise RuntimeError(\"Equal nodes' density!\")\n",
    "        if local_min and not local_max:\n",
    "            return -1\n",
    "        elif local_max and not local_min:\n",
    "            return 1\n",
    "        \n",
    "    # @TODO: paste working algorithm here and adapt it for usage in class\n",
    "    # @FIXME: improve search by removing multy vertex addition in queue\n",
    "    def find_neighbors_local_maxes(self, node_id):\n",
    "        # @CHECKME: remove this condition if it used previously in separate_subclasses()\n",
    "        if self.is_extremum(node_id) == 1:\n",
    "            return {node_id}\n",
    "        \n",
    "        apexes = set()\n",
    "        visited = {node_id}\n",
    "        queue = list(self.neighbors.get(node_id, set()) - visited)\n",
    "        for vertex in queue:\n",
    "            is_local_max = True\n",
    "            visited.add(vertex)\n",
    "            vertex_density = self.nodes[vertex].density\n",
    "            for neighbor_id in self.neighbors[vertex]:\n",
    "                if self.nodes[neighbor_id].density > vertex_density:\n",
    "                    if neighbor_id not in visited:\n",
    "                        queue.append[neighbor_id]\n",
    "                elif is_local_max:\n",
    "                    is_local_max = False\n",
    "                visited.add(neighbor_id)\n",
    "            if is_local_max:\n",
    "                apexes.add(vertex)\n",
    "        return apexes\n",
    "    \n",
    "    def mark_subclasses(self):\n",
    "        pass  # @TODO: if local max found, mark all !min as one class\n",
    "    \n",
    "    # algorithm 3.1\n",
    "    def separate_subclasses(self, visited=set()):\n",
    "        for node_id in self.nodes():\n",
    "            node_is_extremum = self.is_extremum(node_id)\n",
    "            if not node_is_extremum:\n",
    "                pass\n",
    "            elif node_is_extremum == 1:\n",
    "                self.nodes[node_id].subclass_id = node_id\n",
    "                visited.add(node_id)\n",
    "                neighbors = self.find_neighbors(node_id)\n",
    "                for neighbor_id\n",
    "            else:\n",
    "                pass\n",
    "    \n",
    "    def remove_noise(self):\n",
    "        pass # @TODO\n",
    "\n",
    "    def predict(self, input_signal):\n",
    "        pass  # @TODO: make predictions\n",
    "\n",
    "    def update(self):\n",
    "        pass  # @TODO: update topology\n",
    "    \n",
    "    def current_state(self):\n",
    "        return {\n",
    "            'count_signals': self.count_signals,\n",
    "            'C1': self.C1,\n",
    "            'C2': self.C2,\n",
    "            'lambda': self.learning_step,\n",
    "            'forget': self.forget,\n",
    "            'max_age': self.max_age,\n",
    "            'metrics': self.metrics,\n",
    "            'learning_rate_winner': self.rate,\n",
    "            'learning_rate_winner_neighbor': self.rate_neighbor,\n",
    "            'nodes': self.nodes,  # think about it\n",
    "            'neighbors': self.neighbors,\n",
    "            'edges': self.edges\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tests\n",
    "@TODO: Should be automated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST nodes feature vector and density:\n",
      "node 0 : [ 2.  2.] | density 0.04\n",
      "node 1 : [ 4.97  2.  ] | density 0\n",
      "\n",
      "TEST neighbours for nodes:\n",
      "neighbors for node 0 = {1}\n",
      "neighbors for node 1 = {0}\n",
      "\n",
      "TEST edges between nodes:\n",
      "edge between winners (node 0, node 1) = 0\n",
      "edge between winners (None) = None\n"
     ]
    }
   ],
   "source": [
    "input_signal = np.array([2, 2])  # [2,19] for node&edge creation\n",
    "nn = EnhancedSelfOrganizingIncrementalNN([[1, 2], [5, 2]])\n",
    "\n",
    "nn.fit(input_signal)\n",
    "# test for old edge removal\n",
    "# nn.edges[(0,1)] = 51\n",
    "# nn.remove_old_ages()\n",
    "\n",
    "nn_info = nn.current_state()  # this is more correct\n",
    "\n",
    "print(\"TEST nodes feature vector and density:\")\n",
    "for i in nn_info['nodes'].keys():\n",
    "    print(f\"node {i} : {nn_info['nodes'][i].feature_vector} | density {nn_info['nodes'][i].density}\")\n",
    "\n",
    "print(\"\\nTEST neighbours for nodes:\")\n",
    "for i in range(len(nn_info['neighbors'])):\n",
    "    print(f\"neighbors for node {i} = {nn_info['neighbors'].get(i, None)}\")\n",
    "\n",
    "print(\"\\nTEST edges between nodes:\")\n",
    "print(f\"edge between winners (node 0, node 1) = {nn_info['edges'].get((0,1))}\")\n",
    "print(f\"edge between winners (None) = {nn_info['edges'].get(())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'density': {1: 15,\n",
       "  2: 10,\n",
       "  3: 2,\n",
       "  4: 2,\n",
       "  5: 5,\n",
       "  6: 7,\n",
       "  7: 4,\n",
       "  8: 3,\n",
       "  9: 3,\n",
       "  10: 3,\n",
       "  11: 1,\n",
       "  12: 2,\n",
       "  13: 4,\n",
       "  14: 3,\n",
       "  15: 4,\n",
       "  16: 2,\n",
       "  17: 5,\n",
       "  18: 6,\n",
       "  19: 5,\n",
       "  20: 4,\n",
       "  21: 3,\n",
       "  22: 2,\n",
       "  23: 1,\n",
       "  24: 2,\n",
       "  25: 3,\n",
       "  26: 1,\n",
       "  27: 1,\n",
       "  28: 1,\n",
       "  29: 2,\n",
       "  30: 2,\n",
       "  31: 1,\n",
       "  32: 2,\n",
       "  33: 1,\n",
       "  34: 2},\n",
       " 'nodes': {1: {16, 17, 26, 27, 28},\n",
       "  2: {12, 13, 30, 31, 34},\n",
       "  3: {11},\n",
       "  4: {11},\n",
       "  5: {11, 12, 13, 14, 15},\n",
       "  6: {13, 14, 15, 18, 30},\n",
       "  7: {23, 24, 25, 26, 27},\n",
       "  8: {26, 27, 28, 29, 30, 31},\n",
       "  9: {29, 30, 31, 32},\n",
       "  10: {31, 32},\n",
       "  11: {3, 4, 5},\n",
       "  12: {2, 5, 13, 14, 15},\n",
       "  13: {2, 5, 6, 12, 14, 16, 17, 26},\n",
       "  14: {5, 6, 12, 13, 15, 16, 17},\n",
       "  15: {5, 6, 12, 14, 16, 17},\n",
       "  16: {1, 13, 14, 15},\n",
       "  17: {1, 13, 14, 15, 18},\n",
       "  18: {6, 17, 19},\n",
       "  19: {18, 20, 21},\n",
       "  20: {19, 21},\n",
       "  21: {19, 20, 22, 23},\n",
       "  22: {21, 23},\n",
       "  23: {7, 21, 22, 24},\n",
       "  24: {7, 23, 25},\n",
       "  25: {7, 24, 26, 27},\n",
       "  26: {1, 7, 8, 13, 25, 29, 30},\n",
       "  27: {1, 7, 8, 25, 29, 30},\n",
       "  28: {1, 8, 29, 30},\n",
       "  29: {8, 9, 26, 27, 28, 31},\n",
       "  30: {2, 6, 8, 9, 26, 27, 28, 31},\n",
       "  31: {2, 8, 9, 10, 29, 30},\n",
       "  32: {9, 10, 33},\n",
       "  33: {32, 34},\n",
       "  34: {2, 33}}}"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "with open(r\"src/suspended_undirected_graph\", \"rb\") as file:\n",
    "    g = pickle.load(file)\n",
    "g['density'][13] = 4\n",
    "g\n",
    "# with open(r\"src/suspended_undirected_graph\", \"wb\") as file:\n",
    "#     pickle.dump(g, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_neighbors_local_maxes(g, node_id):\n",
    "    apexes = set()\n",
    "    visited = {node_id}\n",
    "    \n",
    "    queue = []\n",
    "    node_density = g['density'][node_id]\n",
    "    for neighbor_id in g['nodes'].get(node_id, set()) - visited:\n",
    "        if g['density'][neighbor_id] > node_density:\n",
    "            queue.append(neighbor_id)\n",
    "        visited.add(neighbor_id)\n",
    "    \n",
    "    for vertex in queue:\n",
    "        is_local_max = True\n",
    "        vertex_density = g['density'][vertex]\n",
    "        for neighbor_id in g['nodes'][vertex]:\n",
    "            if g['density'][neighbor_id] > vertex_density:\n",
    "                if neighbor_id not in visited:\n",
    "                    queue.append(neighbor_id)\n",
    "                is_local_max = False\n",
    "            visited.add(neighbor_id)\n",
    "        if is_local_max:\n",
    "            apexes.add(vertex)\n",
    "        visited.add(vertex)\n",
    "    return apexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 loops, best of 3: 292 µs per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "d = {}\n",
    "for i in range(34):\n",
    "    d[i+1] = find_neighbors_local_maxes(g, i+1)\n",
    "#     print(f\"{i+1:<6}{find_neighbors_local_maxes(g, i+1)}\")\n",
    "# print(d == check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "check = {1: set(),\n",
    " 2: set(),\n",
    " 3: set(),\n",
    " 4: set(),\n",
    " 5: set(),\n",
    " 6: set(),\n",
    " 7: set(),\n",
    " 8: set(),\n",
    " 9: set(),\n",
    " 10: set(),\n",
    " 11: {3, 4, 5},\n",
    " 12: {1, 2, 5, 6},\n",
    " 13: {1, 2, 5, 6},\n",
    " 14: {1, 2, 5, 6},\n",
    " 15: {1, 5, 6},\n",
    " 16: {1, 2, 5, 6},\n",
    " 17: {1, 6},\n",
    " 18: {6},\n",
    " 19: {6},\n",
    " 20: {6},\n",
    " 21: {6},\n",
    " 22: {6},\n",
    " 23: {6, 7},\n",
    " 24: {7},\n",
    " 25: {7},\n",
    " 26: {1, 2, 5, 6, 7, 8, 9},\n",
    " 27: {1, 2, 6, 7, 8, 9},\n",
    " 28: {1, 2, 6, 8, 9},\n",
    " 29: {8, 9},\n",
    " 30: {2, 6, 8, 9},\n",
    " 31: {2, 6, 8, 9, 10},\n",
    " 32: {9, 10},\n",
    " 33: {2, 9, 10},\n",
    " 34: {2}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
