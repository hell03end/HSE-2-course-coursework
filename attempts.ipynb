{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Materials\n",
    "* [Bunch of articles](http://www.mitpressjournals.org/doi/pdf/10.1162/neco.1993.5.6.954) - I strongly recomment this resource, cause it hosts most actual (by year of publishing) articles.\n",
    "* [realization on C++](https://github.com/BelBES/ESOINN)\n",
    "* [ESOINN algorithm](http://cs.nju.edu.cn/rinc/SOINN/e-soinn.pdf)\n",
    "* [Detailed article](http://www.haselab.info/soinn-e.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ESOINN node class\n",
    "##### Fields\n",
    "* feature_vector – weights\n",
    "* accamulate_signals – number of signals\n",
    "* total_points – points $\\neq$ number of signals\n",
    "* density – mean accumulated signals\n",
    "* subclass_id – mark for subclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ESOINN_Node:\n",
    "    def __init__(self, feature_vector=()):\n",
    "        self.feature_vector = np.array(feature_vector, dtype=float)  \n",
    "        self.accamulate_signals = 0\n",
    "        self.total_points = 0\n",
    "        self.density = 0\n",
    "        self.subclass_id = -1\n",
    "    \n",
    "    def update_accamulate_signals(self, n=1):\n",
    "        self.accamulate_signals += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ESOINN Neural Network class\n",
    "To start lerning use: `fit()` method, for clasterization use `predict()`.\n",
    "\n",
    "##### Params:\n",
    "To create new `EnhancedSelfOrganizingIncrementalNN` object – initialize it with first two nodes (`init_nodes`) randomly.\n",
    "\n",
    "##### Hiperparams:\n",
    "* `C1`, `C2` – coefficents for noise deletion.\n",
    "* `learning_step` – number of iterations before remove old ages and find classes ($\\lambda$ in literature).\n",
    "* `max_age` – for edges.\n",
    "* `forget` – specify which N is used in density calculation.\n",
    "* `metrics` – lambda(x, y, axis)\n",
    "* `radius_cut_off` – degree of neighbors' nodes.\n",
    "* `learning_rate_winner` \n",
    "* `learning_rate_winner_neighbor`\n",
    "\n",
    "##### Fields:\n",
    "* `ids` – last given id for nodes (should be unique)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class EnhancedSelfOrganizingIncrementalNN:\n",
    "    def __init__(self, init_nodes, C1=0.001, C2=1, learning_step=200, max_age=50, \n",
    "                 metrics=lambda x,y,axis=0: np.sqrt(np.sum(np.square(np.array(x) - np.array(y)), axis=axis)),\n",
    "                 forget=False, radius_cut_off=1, learning_rate_winner=lambda t: 1/t, \n",
    "                 learning_rate_winner_neighbor=lambda t: 1/(100*t)):\n",
    "        self.C1 = C1\n",
    "        self.C2 = C2\n",
    "        self.learning_step = learning_step\n",
    "        self.max_age = max_age\n",
    "        self.signals_amount = 2\n",
    "        self.metrics = metrics\n",
    "        self.forget = forget\n",
    "        self.unique_id = 2\n",
    "        self.rc = radius_cut_off\n",
    "        self.learning_rate_winner = learning_rate_winner\n",
    "        self.learning_rate_winner_neighbor = learning_rate_winner_neighbor\n",
    "        \n",
    "        self.nodes = {i: ESOINN_Node(init_nodes[i]) for i in (0, 1)}\n",
    "        self.neighbors = {}  # keys = id, values = sets of neighbors' ids\n",
    "        self.edges = {}  # keys = tuples(2), where t[0] < t[1], value = age/None\n",
    "    \n",
    "    def fit(self, input_signal):\n",
    "        self.signals_amount += 1\n",
    "        \n",
    "        winners_ids, distances = self.find_winners(input_signal)\n",
    "        thresholds = [self.calc_threshold(input_signal, winners_ids[i]) for i in (0, 1)]\n",
    "        if distances[0] > thresholds[0] or distances[1] > thresholds[1]:\n",
    "            self.create_node(input_signal)\n",
    "            return\n",
    "        \n",
    "        self.update_edges_age(winners_ids[0])\n",
    "        self.build_connection(winners_ids)\n",
    "        \n",
    "#         @fixme обновление количества побед нейрона - не знаю куда поставить, но точно до подсчета плотности\n",
    "        self.nodes[winners_ids[0]].update_accamulate_signals()\n",
    "        \n",
    "        self.update_density(winners_ids[0])\n",
    "        \n",
    "#         self.nodes[winners_ids[0]].update_accamulate_signals()\n",
    "        \n",
    "#         self.update_feature_vector(winners_ids[0])\n",
    "        \n",
    "#         self.remove_old_ages()\n",
    "        \n",
    "#         if self.signals_amount % self.learning_step == 0:\n",
    "#             self.update_topology()\n",
    "    \n",
    "    def find_winners(self, input_signal):\n",
    "        # @fixme: inf coef and separate variables for each winner\n",
    "        winner1 = float('inf')\n",
    "        winner1_id = -1\n",
    "        winner2 = float('inf')\n",
    "        winner2_id = -1\n",
    "        for node_id in self.nodes:\n",
    "            dist = self.metrics(input_signal, self.nodes[node_id].feature_vector)\n",
    "            if dist <= winner1:\n",
    "                winner1, winner2 = dist, winner1\n",
    "                winner2_id = winner1_id\n",
    "                winner1_id = node_id\n",
    "            elif dist < winner2:\n",
    "                winner2 = dist\n",
    "                winner2_id = node_id\n",
    "        return [winner1_id, winner2_id], [winner1, winner2]\n",
    "    \n",
    "    def find_neighbors(start_node_id, depth=1):\n",
    "        visited = {start_node_id}\n",
    "        queue = list(self.neighbors.get(start, set()) - visited)\n",
    "        while depth:\n",
    "            depth -= 1\n",
    "            for vertex in queue.copy():  # @fixme: do not use copy!\n",
    "                visited.add(vertex)\n",
    "                queue.extend([node for node in self.neighbors[vertex] - visited if node not in visited])\n",
    "        return visited - {start_node_id}    \n",
    "    \n",
    "    def calc_threshold(self, input_signal, winner_id):\n",
    "        neighbors = self.neighbors.get(winner_id, None)\n",
    "        if neighbors:\n",
    "            return np.max([\n",
    "                self.metrics(self.nodes[winner_id].feature_vector, self.nodes[neighbor_id].feature_vector) \n",
    "                for neighbor_id in find_neighbors(winner_id, depth=self.rc)\n",
    "            ])\n",
    "        else:\n",
    "            return self.find_winners(self.nodes[winner_id].feature_vector)[1][1]  # 'cause first winner is always current node\n",
    "    \n",
    "    def create_node(self, input_signal):  \n",
    "        self.nodes[self.unique_id] = ESOINN_Node(input_signal)\n",
    "        self.unique_id += 1  # to provide unique ids for each neuron\n",
    "    \n",
    "    def update_edges_age(self, node_id, step=1):\n",
    "        for neighbor_id in self.neighbors.get(node_id, []):\n",
    "            pair_id = min(node_id, neighbor_id), max(node_id, neighbor_id)\n",
    "            self.edges[pair_id] += 1\n",
    "                \n",
    "    # algorithm 3.2\n",
    "    def build_connection(self, winners_ids):\n",
    "        winner1_class = self.nodes[winners_ids[0]].subclass_id\n",
    "        winner2_class = self.nodes[winners_ids[1]].subclass_id\n",
    "        # case 1-2\n",
    "        if winner1_class == -1 or winner2_class == -1 or winner1_class == winner2_class:\n",
    "            self.create_edge(winners_ids)\n",
    "        # case 3\n",
    "        pass\n",
    "                \n",
    "    def create_edge(self, nodes_ids):\n",
    "        for node_id in nodes_ids:\n",
    "            if node_id not in self.neighbors:\n",
    "                self.neighbors[node_id] = set()\n",
    "            # @CHECKME: for multiply neighbors creation\n",
    "            for insert_id in nodes_ids:\n",
    "                if insert_id != node_id:\n",
    "                    self.neighbors[node_id] |= {insert_id}\n",
    "                    nodes_pair = (min(node_id, insert_id), max(node_id, insert_id))\n",
    "                    self.edges[nodes_pair] = 0\n",
    "    \n",
    "    def remove_edge(self, nodes_ids):\n",
    "        pass  # @todo: edge removal\n",
    "        \n",
    "    # @fixme работает вроде правильно, но может можно еще изящнее сделать? :D\n",
    "    def update_density(self, winner_id):\n",
    "        \n",
    "#       подсчет total_points (Тут очень не здоровое но рабочее дерьмо :D )\n",
    "        self.nodes[winner_id].total_points += 1 / (1 + np.sum([self.metrics(self.nodes[winner_id].feature_vector, \n",
    "            self.nodes[neighbor_id].feature_vector) for neighbor_id in self.neighbors[winner_id]]\n",
    "            )/len(self.neighbors[winner_id]))**2\n",
    "\n",
    "#       подсчет плотности\n",
    "        self.nodes[winner_id].density = self.nodes[winner_id].total_points/self.nodes[winner_id].accamulate_signals\n",
    "\n",
    "    def update_feature_vector(self, winner_id, input_signal):\n",
    "        \n",
    "#       смещение вектора признаков нейрона победителя\n",
    "        self.nodes[winner_id].feature_vector += self.learning_rate_winner(self.nodes[winner_id].accamulate_signals)*(\n",
    "            self.metrics(self.nodes[winner_id].feature_vector, input_signal))\n",
    "\n",
    "#       смещение вектора признаков смежных нейрону победителю\n",
    "        for neighbor_id in self.neighbors[winner_id]:\n",
    "            self.nodes[neighbor_id].feature_vector += self.learning_rate_winner_neighbor(\n",
    "                self.nodes[winner_id].accamulate_signals)*self.metrics(self.nodes[neighbor_id].feature_vector, \n",
    "                input_signal)\n",
    "    \n",
    "    def remove_old_ages(self):\n",
    "        \n",
    "#       удаление ребра и удаление соседей у нейронов, если превышен порог max_age\n",
    "        [(self.neighbors[edge[0]].remove(edge[1]), self.neighbors[edge[1]].remove(edge[0]), self.edges.pop(edge)) \n",
    "         for edge in self.edges.copy() if self.edges[edge] > self.max_age]\n",
    "        \n",
    "#       удаление пустых set-ов у нейронов в neighbor\n",
    "        [self.neighbors.pop(node_id) for node_id in self.nodes if self.neighbors[node_id] == set()]\n",
    "\n",
    "#     def predict(self, input_signal):\n",
    "#         pass\n",
    "\n",
    "#     def update(self):\n",
    "#         pass\n",
    "    \n",
    "    def current_state(self):\n",
    "        return {\n",
    "            'signals_amount': self.signals_amount,\n",
    "            'C1': self.C1,\n",
    "            'C2': self.C2,\n",
    "            'lambda': self.learning_step,\n",
    "            'forget': self.forget,\n",
    "            'max_age': self.max_age,\n",
    "            'metrics': self.metrics,\n",
    "            'learning_rate_winner': self.learning_rate_winner,\n",
    "            'learning_rate_winner_neighbor': self.learning_rate_winner_neighbor,\n",
    "            'nodes': self.nodes,  # think about it\n",
    "            'neighbors': self.neighbors,\n",
    "            'edges': self.edges\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tests\n",
    "@TODO: Should be automated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST nodes feature vector and density:\n",
      "node 0 : [1 2] | density 0.04\n",
      "node 1 : [5 2] | density 0\n",
      "\n",
      "TEST neighbours for nodes:\n",
      "neighbors for node 0 = {1}\n",
      "neighbors for node 1 = {0}\n",
      "\n",
      "TEST edges between nodes:\n",
      "edge between winners (node 0, node 1) = 0\n",
      "edge between winners (None) = None\n"
     ]
    }
   ],
   "source": [
    "input_signal = np.array([2, 2])  # [2,19] for node&edge creation\n",
    "nn = EnhancedSelfOrganizingIncrementalNN([[1, 2], [5, 2]])\n",
    "\n",
    "nn.fit(input_signal)\n",
    "# test for old edge removal\n",
    "# nn.edges[(0,1)] = 51\n",
    "# nn.remove_old_ages()\n",
    "\n",
    "nn_info = nn.current_state()  # this is more correct\n",
    "\n",
    "print(\"TEST nodes feature vector and density:\")\n",
    "for i in nn_info['nodes'].keys():\n",
    "    print(f\"node {i} : {nn_info['nodes'][i].feature_vector} | density {nn_info['nodes'][i].density}\")\n",
    "\n",
    "print(\"\\nTEST neighbours for nodes:\")\n",
    "for i in range(len(nn_info['neighbors'])):\n",
    "    print(f\"neighbors for node {i} = {nn_info['neighbors'].get(i, None)}\")\n",
    "\n",
    "print(\"\\nTEST edges between nodes:\")\n",
    "print(f\"edge between winners (node 0, node 1) = {nn_info['edges'].get((0,1))}\")\n",
    "print(f\"edge between winners (None) = {nn_info['edges'].get(())}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
